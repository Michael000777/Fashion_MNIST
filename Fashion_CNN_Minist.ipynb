{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iuTJwCE7CUQ0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZL_yOIwCaMq",
        "outputId": "c71731c2-79dd-4be6-d5bd-d246adecd41d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "Device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QtiZSHBGCaT7",
        "outputId": "37a4a70d-6318-4c5c-cc5e-2dfb46646818"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "bactch_size = 8\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser/pants', 'Pullover shirt', 'Dress', 'Coat', 'Sandal',\n",
        "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n"
      ],
      "metadata": {
        "id": "tQytw6nLCaXA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = iter(trainset)\n",
        "image, label = next(train_iter)\n",
        "image.shape, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKe5QWbHFR2F",
        "outputId": "fd0febba-b403-4e34-9773-cf587acb3993"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 9)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(image).item(), torch.max(image).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJxCTriIFS8o",
        "outputId": "b539b450-0f22-4298-a181-eee679f6562a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "np_img = image.numpy()\n",
        "print(classes[label])\n",
        "plt.imshow(np_img.reshape((28, 28, 1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "Iars6rGLCaZX",
        "outputId": "fd784fb8-3e9d-46a0-92bc-8c54b46713e6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle boot\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c780af68790>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainset), len(testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KwADeylk28U",
        "outputId": "b9cbf06b-4109-47ab-9c5c-13579053d4f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, valset = torch.utils.data.random_split(trainset, [50000, 10000])\n",
        "len(trainset), len(valset), len(testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eU21sesk3D5",
        "outputId": "4e1ce850-354d-4296-b081-a66dff858d0f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'number of batches in the training set: {int(50000/bactch_size)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stfWDAM7k3Ms",
        "outputId": "536397e8-509f-4e7f-dd31-c64fc19b4c4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of batches in the training set: 6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrlEuXEnk3Pk",
        "outputId": "4012c24f-e877-4eb3-e651-c0f6cd62694f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.Subset"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bactch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=bactch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=bactch_size,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "MEf8ByZ9k3SL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class fash_NeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3)\n",
        "    self.pool1 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3)\n",
        "    self.pool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=2)\n",
        "    self.pool3 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=4096, out_features=1024)\n",
        "    self.drop1 = nn.Dropout(p=0.3)\n",
        "\n",
        "    self.fc2 = nn.Linear(in_features=1024, out_features=1024)\n",
        "    self.drop2 = nn.Dropout(p=0.3)\n",
        "\n",
        "    self.out = nn.Linear(in_features=1024, out_features=10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool3(x)\n",
        "\n",
        "    x = self.flatten(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.drop1(x)\n",
        "\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.drop2(x)\n",
        "\n",
        "    x = self.out(x)\n",
        "\n",
        "\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "SoT6bd0iCab9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = fash_NeuralNet()\n",
        "net.to(Device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNk3YVI_pPNv",
        "outputId": "7f9230dd-98d6-4d6b-fd62-802e262851df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fash_NeuralNet(\n",
              "  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(512, 1024, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "  (drop1): Dropout(p=0.3, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (drop2): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(trainloader):\n",
        "  inputs, labels = data[0].to(Device), data[1].to(Device)\n",
        "  print(f'input shape: {inputs.shape}')\n",
        "  print(f'after network shape: {net(inputs).shape}')\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nc4h3A6pPQV",
        "outputId": "57a6d036-bae6-459d-a1ce-c827c1d6a276"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([8, 1, 28, 28])\n",
            "after network shape: torch.Size([8, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training our CNN Classifier**"
      ],
      "metadata": {
        "id": "t71caagM2fnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "tmjiDBfgr-Vc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch():\n",
        "  net.train(True)\n",
        "\n",
        "  running_loss = 0.0\n",
        "  running_accuracy = 0.0\n",
        "\n",
        "  for batch_idx, data in enumerate(trainloader):\n",
        "    inputs, labels = data[0].to(Device), data[1].to(Device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(inputs) # shape: [batch_size, 10]\n",
        "    correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "    running_accuracy += correct/bactch_size\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx % 500 == 499: #printing every 500 batch\n",
        "      avg_loss_across_batches = running_loss / 500\n",
        "      avg_acc_across_batches = (running_accuracy/500) * 100\n",
        "      print('Batch {0}, Loss: {1:.3f}, Accuracy: {2:.1f}%'.format(batch_idx,\n",
        "                                                                  avg_loss_across_batches,\n",
        "                                                                  avg_acc_across_batches))\n",
        "      running_loss = 0.0\n",
        "      running_accuracy = 0.0\n",
        "\n",
        "print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNusEAVz4Yl9",
        "outputId": "825e18a3-a295-4193-f369-d1d555a028a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_one_epoch():\n",
        "    net.train(False)\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "\n",
        "    for i, data in enumerate(valloader):\n",
        "        inputs, labels = data[0].to(Device), data[1].to(Device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = net(inputs) # shape: [batch_size, 10]\n",
        "            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "            running_accuracy += correct / bactch_size\n",
        "            loss = criterion(outputs, labels) # One number, the average batch loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    avg_loss_across_batches = running_loss / len(valloader)\n",
        "    avg_acc_across_batches = (running_accuracy / len(valloader)) * 100\n",
        "\n",
        "    print('Val Loss: {0:.3f}, Val Accuracy: {1:.1f}%'.format(avg_loss_across_batches,\n",
        "                                                            avg_acc_across_batches))\n",
        "    print('***************************************************')\n",
        "    print()"
      ],
      "metadata": {
        "id": "i6FIaGFu_rWH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch_idx in range(epochs):\n",
        "  print(f'Epoch: {epoch_idx + 1}\\n')\n",
        "\n",
        "  train_one_epoch()\n",
        "\n",
        "  validate_one_epoch()\n",
        "\n",
        "print(\"Training Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPELWC4vr-Xj",
        "outputId": "9658dd2a-f384-4362-e32d-11eb1fb6b9af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "\n",
            "Batch 499, Loss: 1.180, Accuracy: 55.0%\n",
            "Batch 999, Loss: 0.725, Accuracy: 72.4%\n",
            "Batch 1499, Loss: 0.614, Accuracy: 76.7%\n",
            "Batch 1999, Loss: 0.607, Accuracy: 77.8%\n",
            "Batch 2499, Loss: 0.560, Accuracy: 78.9%\n",
            "Batch 2999, Loss: 0.507, Accuracy: 80.7%\n",
            "Batch 3499, Loss: 0.505, Accuracy: 81.4%\n",
            "Batch 3999, Loss: 0.459, Accuracy: 83.0%\n",
            "Batch 4499, Loss: 0.473, Accuracy: 82.5%\n",
            "Batch 4999, Loss: 0.445, Accuracy: 83.6%\n",
            "Batch 5499, Loss: 0.429, Accuracy: 84.2%\n",
            "Batch 5999, Loss: 0.405, Accuracy: 85.6%\n",
            "Val Loss: 0.394, Val Accuracy: 85.2%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Batch 499, Loss: 0.403, Accuracy: 85.0%\n",
            "Batch 999, Loss: 0.377, Accuracy: 85.7%\n",
            "Batch 1499, Loss: 0.381, Accuracy: 86.0%\n",
            "Batch 1999, Loss: 0.386, Accuracy: 86.0%\n",
            "Batch 2499, Loss: 0.343, Accuracy: 87.2%\n",
            "Batch 2999, Loss: 0.322, Accuracy: 88.0%\n",
            "Batch 3499, Loss: 0.337, Accuracy: 88.1%\n",
            "Batch 3999, Loss: 0.334, Accuracy: 87.8%\n",
            "Batch 4499, Loss: 0.328, Accuracy: 88.2%\n",
            "Batch 4999, Loss: 0.362, Accuracy: 86.8%\n",
            "Batch 5499, Loss: 0.318, Accuracy: 88.4%\n",
            "Batch 5999, Loss: 0.301, Accuracy: 89.2%\n",
            "Val Loss: 0.326, Val Accuracy: 88.1%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Batch 499, Loss: 0.285, Accuracy: 89.8%\n",
            "Batch 999, Loss: 0.327, Accuracy: 88.1%\n",
            "Batch 1499, Loss: 0.284, Accuracy: 89.4%\n",
            "Batch 1999, Loss: 0.280, Accuracy: 89.8%\n",
            "Batch 2499, Loss: 0.269, Accuracy: 90.1%\n",
            "Batch 2999, Loss: 0.307, Accuracy: 88.7%\n",
            "Batch 3499, Loss: 0.287, Accuracy: 90.1%\n",
            "Batch 3999, Loss: 0.285, Accuracy: 89.6%\n",
            "Batch 4499, Loss: 0.269, Accuracy: 90.3%\n",
            "Batch 4999, Loss: 0.288, Accuracy: 89.3%\n",
            "Batch 5499, Loss: 0.263, Accuracy: 90.5%\n",
            "Batch 5999, Loss: 0.272, Accuracy: 90.2%\n",
            "Val Loss: 0.294, Val Accuracy: 89.2%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "Batch 499, Loss: 0.242, Accuracy: 91.1%\n",
            "Batch 999, Loss: 0.247, Accuracy: 90.7%\n",
            "Batch 1499, Loss: 0.268, Accuracy: 89.5%\n",
            "Batch 1999, Loss: 0.237, Accuracy: 91.2%\n",
            "Batch 2499, Loss: 0.253, Accuracy: 90.7%\n",
            "Batch 2999, Loss: 0.249, Accuracy: 91.0%\n",
            "Batch 3499, Loss: 0.245, Accuracy: 91.0%\n",
            "Batch 3999, Loss: 0.239, Accuracy: 91.5%\n",
            "Batch 4499, Loss: 0.239, Accuracy: 91.2%\n",
            "Batch 4999, Loss: 0.240, Accuracy: 91.3%\n",
            "Batch 5499, Loss: 0.255, Accuracy: 90.7%\n",
            "Batch 5999, Loss: 0.254, Accuracy: 91.0%\n",
            "Val Loss: 0.271, Val Accuracy: 90.2%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 5\n",
            "\n",
            "Batch 499, Loss: 0.219, Accuracy: 92.2%\n",
            "Batch 999, Loss: 0.211, Accuracy: 92.4%\n",
            "Batch 1499, Loss: 0.212, Accuracy: 92.5%\n",
            "Batch 1999, Loss: 0.224, Accuracy: 91.7%\n",
            "Batch 2499, Loss: 0.216, Accuracy: 92.1%\n",
            "Batch 2999, Loss: 0.219, Accuracy: 92.0%\n",
            "Batch 3499, Loss: 0.221, Accuracy: 92.2%\n",
            "Batch 3999, Loss: 0.234, Accuracy: 91.3%\n",
            "Batch 4499, Loss: 0.205, Accuracy: 92.2%\n",
            "Batch 4999, Loss: 0.219, Accuracy: 91.6%\n",
            "Batch 5499, Loss: 0.222, Accuracy: 92.3%\n",
            "Batch 5999, Loss: 0.214, Accuracy: 92.0%\n",
            "Val Loss: 0.264, Val Accuracy: 90.5%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 6\n",
            "\n",
            "Batch 499, Loss: 0.174, Accuracy: 93.5%\n",
            "Batch 999, Loss: 0.190, Accuracy: 92.8%\n",
            "Batch 1499, Loss: 0.207, Accuracy: 92.1%\n",
            "Batch 1999, Loss: 0.192, Accuracy: 92.8%\n",
            "Batch 2499, Loss: 0.193, Accuracy: 92.9%\n",
            "Batch 2999, Loss: 0.190, Accuracy: 93.2%\n",
            "Batch 3499, Loss: 0.198, Accuracy: 92.5%\n",
            "Batch 3999, Loss: 0.199, Accuracy: 93.0%\n",
            "Batch 4499, Loss: 0.181, Accuracy: 92.8%\n",
            "Batch 4999, Loss: 0.192, Accuracy: 92.9%\n",
            "Batch 5499, Loss: 0.176, Accuracy: 93.2%\n",
            "Batch 5999, Loss: 0.190, Accuracy: 93.0%\n",
            "Val Loss: 0.253, Val Accuracy: 91.3%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 7\n",
            "\n",
            "Batch 499, Loss: 0.157, Accuracy: 94.3%\n",
            "Batch 999, Loss: 0.173, Accuracy: 93.6%\n",
            "Batch 1499, Loss: 0.160, Accuracy: 94.3%\n",
            "Batch 1999, Loss: 0.171, Accuracy: 93.4%\n",
            "Batch 2499, Loss: 0.154, Accuracy: 94.0%\n",
            "Batch 2999, Loss: 0.174, Accuracy: 93.9%\n",
            "Batch 3499, Loss: 0.160, Accuracy: 93.8%\n",
            "Batch 3999, Loss: 0.169, Accuracy: 93.7%\n",
            "Batch 4499, Loss: 0.171, Accuracy: 93.6%\n",
            "Batch 4999, Loss: 0.180, Accuracy: 93.3%\n",
            "Batch 5499, Loss: 0.160, Accuracy: 94.2%\n",
            "Batch 5999, Loss: 0.166, Accuracy: 94.1%\n",
            "Val Loss: 0.251, Val Accuracy: 91.7%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 8\n",
            "\n",
            "Batch 499, Loss: 0.137, Accuracy: 94.8%\n",
            "Batch 999, Loss: 0.133, Accuracy: 94.7%\n",
            "Batch 1499, Loss: 0.160, Accuracy: 93.5%\n",
            "Batch 1999, Loss: 0.132, Accuracy: 94.7%\n",
            "Batch 2499, Loss: 0.154, Accuracy: 94.2%\n",
            "Batch 2999, Loss: 0.150, Accuracy: 94.5%\n",
            "Batch 3499, Loss: 0.151, Accuracy: 94.3%\n",
            "Batch 3999, Loss: 0.141, Accuracy: 94.8%\n",
            "Batch 4499, Loss: 0.141, Accuracy: 94.9%\n",
            "Batch 4999, Loss: 0.143, Accuracy: 94.8%\n",
            "Batch 5499, Loss: 0.161, Accuracy: 94.0%\n",
            "Batch 5999, Loss: 0.158, Accuracy: 94.2%\n",
            "Val Loss: 0.251, Val Accuracy: 91.5%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 9\n",
            "\n",
            "Batch 499, Loss: 0.120, Accuracy: 95.3%\n",
            "Batch 999, Loss: 0.126, Accuracy: 95.2%\n",
            "Batch 1499, Loss: 0.113, Accuracy: 95.9%\n",
            "Batch 1999, Loss: 0.128, Accuracy: 95.0%\n",
            "Batch 2499, Loss: 0.132, Accuracy: 95.0%\n",
            "Batch 2999, Loss: 0.131, Accuracy: 95.1%\n",
            "Batch 3499, Loss: 0.136, Accuracy: 95.0%\n",
            "Batch 3999, Loss: 0.139, Accuracy: 94.6%\n",
            "Batch 4499, Loss: 0.133, Accuracy: 95.0%\n",
            "Batch 4999, Loss: 0.127, Accuracy: 95.2%\n",
            "Batch 5499, Loss: 0.121, Accuracy: 95.3%\n",
            "Batch 5999, Loss: 0.125, Accuracy: 95.4%\n",
            "Val Loss: 0.271, Val Accuracy: 91.1%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 10\n",
            "\n",
            "Batch 499, Loss: 0.096, Accuracy: 96.6%\n",
            "Batch 999, Loss: 0.114, Accuracy: 95.7%\n",
            "Batch 1499, Loss: 0.106, Accuracy: 96.2%\n",
            "Batch 1999, Loss: 0.116, Accuracy: 95.6%\n",
            "Batch 2499, Loss: 0.107, Accuracy: 95.8%\n",
            "Batch 2999, Loss: 0.107, Accuracy: 96.1%\n",
            "Batch 3499, Loss: 0.106, Accuracy: 95.6%\n",
            "Batch 3999, Loss: 0.115, Accuracy: 95.7%\n",
            "Batch 4499, Loss: 0.114, Accuracy: 95.7%\n",
            "Batch 4999, Loss: 0.121, Accuracy: 95.8%\n",
            "Batch 5499, Loss: 0.122, Accuracy: 95.5%\n",
            "Batch 5999, Loss: 0.119, Accuracy: 95.2%\n",
            "Val Loss: 0.292, Val Accuracy: 91.1%\n",
            "***************************************************\n",
            "\n",
            "Training Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data(testloader):\n",
        "    net.eval()\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "\n",
        "    for i, data in enumerate(testloader):\n",
        "        inputs, labels = data[0].to(Device), data[1].to(Device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = net(inputs) # shape: [batch_size, 10]\n",
        "            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "            running_accuracy += correct / bactch_size\n",
        "            loss = criterion(outputs, labels) # One number, the average batch loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    avg_loss_across_batches = running_loss / len(testloader)\n",
        "    avg_acc_across_batches = (running_accuracy / len(testloader)) * 100\n",
        "\n",
        "    print('Test Loss: {0:.3f}, Test Accuracy: {1:.1f}%'.format(avg_loss_across_batches,\n",
        "                                                            avg_acc_across_batches))\n",
        "    print('***************************************************')\n",
        "    print()"
      ],
      "metadata": {
        "id": "867Y7_wvr-aF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data(testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4zZWqypr-cs",
        "outputId": "4389f72b-f4ba-4d77-b71f-7bc881441377"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.306, Test Accuracy: 91.1%\n",
            "***************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R083-y6NpPSt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DmTNh8g_pPVT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3TyBoDZCae0"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}